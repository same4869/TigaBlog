# 服务全局端口
server:
  port: 80


# 日志相关
logging:
  # 日志输出等级
  level:
    com.xun:
      trace
  # 日志输出路径
#  path:
#    ./tigalog/
  pattern:
    # 控制台日志输出格式
#    console:
#      "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n"
    # 文件日志输出格式
    file:
      "%d{yyyy-MM-dd HH:mm:ss.SSS} === [%thread] === %-5level === %logger{50} ==== %msg%n"

# 数据库相关
spring:
  datasource:
#   数据源基本配置
    username: root
    password: wangxun0902
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://106.14.133.223:3306/tiga_blog
    type: com.alibaba.druid.pool.DruidDataSource
#   数据源其他配置
    initialSize: 5
    minIdle: 5
    maxActive: 20
    maxWait: 60000
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
#   配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
    filters: stat,wall
    #,log4j
    maxPoolPreparedStatementPerConnectionSize: 20
    useGlobalDataSourceStat: true
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500


# THYMELEAF
  thymeleaf:
    encoding: UTF-8
  # 热部署静态文件
    cache: false
  # 使用HTML5标准
    mode: HTML5

# JPA 自动删表建表，根据domain下面的实体类
  jpa:
    show-sql: true
    hibernate:
      ddl-auto: update
#      create 启动时删数据库中的表，然后创建，退出时不删除数据表
#      create-drop 启动时删数据库中的表，然后创建，退出时删除数据表 如果表不存在报错
#      update 如果启动时表格式不一致则更新表，原有数据保留
#      validate 项目启动表结构进行校验 如果不一致则报错

# Elasticsearch远程服务
  data:
    elasticsearch:
      cluster-nodes: 106.14.133.223:9300
      # 设置连接超时时间
      properties:
        transport:
          tcp:
            connect_timeout: 120s

debug: false
